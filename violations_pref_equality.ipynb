{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Violations of Preferential Equality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pref_voting.generate_profiles import * \n",
    "from pref_voting.voting_methods import *\n",
    "from pref_voting.rankings import *\n",
    "from pref_voting.profiles_with_ties import ProfileWithTies\n",
    "from pref_voting.iterative_methods import top_n_instant_runoff_for_truncated_linear_orders\n",
    "\n",
    "import glob\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import io\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_ranking_extended_strict_pref(ranking1, ranking2, candidates): \n",
    "    # check if ranking1 and ranking2 have the same ranking of candidates\n",
    "    for c1 in candidates:\n",
    "        for c2 in candidates:\n",
    "            if not ranking1.extended_strict_pref(c1, c2) and ranking2.extended_strict_pref(c1, c2):\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def get_winner_runner_up_loser(profile): \n",
    "\n",
    "    pl_scores = profile.plurality_scores()\n",
    "    # find the 2nd largest plurality score\n",
    "    second_pl_score = sorted(set(pl_scores.values()))[1]\n",
    "    second_place_cand = [c for c in pl_scores.keys() if pl_scores[c] == second_pl_score][0]\n",
    "    first_pl_score = sorted(set(pl_scores.values()))[0]\n",
    "    first_place_cand = [c for c in pl_scores.keys() if pl_scores[c] == first_pl_score][0]\n",
    "\n",
    "    winner = instant_runoff_for_truncated_linear_orders(profile)[0]\n",
    "\n",
    "    runner_up = second_place_cand if winner == first_place_cand else first_place_cand\n",
    "\n",
    "    loser = [c for c in profile.candidates if c not in [winner, runner_up]][0]\n",
    "\n",
    "    return winner, runner_up, loser\n",
    "\n",
    "def has_irv_preferential_equality_violation(profile, winner, runner_up, loser): \n",
    "\n",
    "    bca = Ranking({\n",
    "        runner_up:1, \n",
    "        loser:2, \n",
    "        winner:3})\n",
    "    \n",
    "    bac = Ranking({\n",
    "        runner_up:1, \n",
    "        winner:2, \n",
    "        loser:3})\n",
    "    \n",
    "    acb = Ranking({\n",
    "        winner:1, \n",
    "        loser:2, \n",
    "        runner_up:3})\n",
    "    \n",
    "    cab = Ranking({\n",
    "        loser:1, \n",
    "        winner:2, \n",
    "        runner_up:3})\n",
    "\n",
    "    rankings, rcounts = profile.rankings_counts\n",
    "\n",
    "    num_bca = 0\n",
    "    num_bac = 0\n",
    "    for r, c in zip(rankings, rcounts): \n",
    "        if same_ranking_extended_strict_pref(r, bca, profile.candidates):\n",
    "            num_bca += c\n",
    "        if same_ranking_extended_strict_pref(r, bac, profile.candidates):\n",
    "            num_bac += c\n",
    "    num = max(num_bca, num_bac)\n",
    "\n",
    "    bac_violation = num == num_bac\n",
    "    # print('num is ', num)\n",
    "    new_rankings = []\n",
    "    new_counts = []\n",
    "    # print(\"acb is \", acb)\n",
    "    acb_rankings = [r for r in profile.rankings if same_ranking_extended_strict_pref(r, acb, profile.candidates)]\n",
    "\n",
    "    # print(len(acb_rankings))\n",
    "    new_rankings.append(cab)\n",
    "    new_counts.append(len(acb_rankings[:num]))\n",
    "    new_rankings.append(acb)\n",
    "    new_counts.append(len(acb_rankings[num:]))\n",
    "    for r,c in zip(rankings, rcounts):\n",
    "        if not same_ranking_extended_strict_pref(r, acb, profile.candidates):\n",
    "            new_rankings.append(r)\n",
    "            new_counts.append(c)\n",
    "\n",
    "    new_prof = ProfileWithTies(new_rankings, new_counts)\n",
    "    # new_prof.anonymize().display()\n",
    "    # print(loser)\n",
    "    # print(instant_runoff_for_truncated_linear_orders(ProfileWithTies(new_rankings, new_counts)))\n",
    "\n",
    "    return loser in instant_runoff_for_truncated_linear_orders(new_prof), bac_violation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_violations(profiles): \n",
    "\n",
    "    num_profs = 0\n",
    "    num_profs_no_absolute_maj_winner = 0\n",
    "\n",
    "    num_orig_prof_violations = 0  \n",
    "    num_modified_prof_violations = 0  \n",
    "\n",
    "    for prof in tqdm(profiles): \n",
    "\n",
    "        if not prof.is_truncated_linear: \n",
    "            continue\n",
    "        prof.remove_empty_rankings() \n",
    "\n",
    "        top_three = top_n_instant_runoff_for_truncated_linear_orders(prof, 3)\n",
    "\n",
    "        restricted_prof = prof.remove_candidates([c for c in prof.candidates if c not in top_three])\n",
    "\n",
    "        restricted_prof.remove_empty_rankings() \n",
    "        \n",
    "        if len(restricted_prof.candidates) < 3:\n",
    "            continue\n",
    "\n",
    "        irv_ws = instant_runoff_for_truncated_linear_orders(restricted_prof)\n",
    "\n",
    "        if len(irv_ws) != 1: \n",
    "            continue\n",
    "        \n",
    "        num_profs += 1\n",
    "\n",
    "        absolute_majority_winner = absolute_majority(restricted_prof)\n",
    "        if len(absolute_majority_winner) == 1: \n",
    "            continue\n",
    "\n",
    "        num_profs_no_absolute_maj_winner += 1\n",
    "\n",
    "        winner, runner_up, loser = get_winner_runner_up_loser(restricted_prof)\n",
    "\n",
    "        has_violation, orig_prof_violation =  has_irv_preferential_equality_violation(restricted_prof, winner, runner_up, loser)\n",
    "\n",
    "        if has_violation and orig_prof_violation:\n",
    "            num_orig_prof_violations += 1\n",
    "\n",
    "        if has_violation and not orig_prof_violation: \n",
    "            num_modified_prof_violations += 1\n",
    "\n",
    "    print(f\"{num_profs_no_absolute_maj_winner} out of {num_profs} profiles have no absolute majority winner: {num_profs_no_absolute_maj_winner/num_profs}\\n\")\n",
    "\n",
    "    print(f\"Type 1: Original Profile Violations\\n{num_orig_prof_violations} violations out of {num_profs_no_absolute_maj_winner} profiles: {num_orig_prof_violations/num_profs_no_absolute_maj_winner}\\n\")\n",
    "\n",
    "    print(f\"Type 2: Modified Profile Violations\\n{num_modified_prof_violations} violations out of {num_profs_no_absolute_maj_winner} profiles: {num_modified_prof_violations/num_profs_no_absolute_maj_winner}\\n\")\n",
    "\n",
    "    print(f\"Total Violations\\n{(num_orig_prof_violations + num_modified_prof_violations)} violations out of {num_profs_no_absolute_maj_winner} profiles: {(num_orig_prof_violations + num_modified_prof_violations)/num_profs_no_absolute_maj_winner}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757701dd16784b5cadae4ad0e8f999f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 profiles have no absolute majority winner: 1.0\n",
      "\n",
      "Type 1: Original Profile Violations\n",
      "605 violations out of 1000 profiles: 0.605\n",
      "\n",
      "Type 2: Modified Profile Violations\n",
      "186 violations out of 1000 profiles: 0.186\n",
      "\n",
      "Total Violations\n",
      "791 violations out of 1000 profiles: 0.791\n"
     ]
    }
   ],
   "source": [
    "num_trials = 100_000\n",
    "num_cands = 3\n",
    "num_voters = 1001\n",
    "\n",
    "profiles = [generate_profile(num_cands, num_voters).to_profile_with_ties() for _ in range(1000)]\n",
    "\n",
    "find_violations(profiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stable Voting Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0f858adfc743329ccaf4b5c5cda24e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/657 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 out of 197 profiles have no absolute majority winner: 0.30456852791878175\n",
      "\n",
      "Type 1: Original Profile Violations\n",
      "37 violations out of 60 profiles: 0.6166666666666667\n",
      "\n",
      "Type 2: Modified Profile Violations\n",
      "11 violations out of 60 profiles: 0.18333333333333332\n",
      "\n",
      "Total Violations\n",
      "48 violations out of 60 profiles: 0.8\n"
     ]
    }
   ],
   "source": [
    "profiles = [ProfileWithTies.read(fname) for fname in glob.glob('real_elections/stable_voting_dataset/*')]\n",
    "\n",
    "find_violations(profiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preflib Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05bb7add15b3498193079822079b2d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/308 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf8796b13d14802971ef3abeec44734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e9db9132c654abd8fbbb0c483f5ed5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf6edc0ee1440028a3ad298fbd1e79e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 out of 308 profiles have no absolute majority winner: 0.33766233766233766\n",
      "\n",
      "Type 1: Original Profile Violations\n",
      "28 violations out of 104 profiles: 0.2692307692307692\n",
      "\n",
      "Type 2: Modified Profile Violations\n",
      "30 violations out of 104 profiles: 0.28846153846153844\n",
      "\n",
      "Total Violations\n",
      "58 violations out of 104 profiles: 0.5576923076923077\n"
     ]
    }
   ],
   "source": [
    "profiles = []\n",
    "elections = []\n",
    "file_names = []\n",
    "for fname in tqdm(glob.glob(\"real_elections/preflib_dataset/*.soi\")):\n",
    "\n",
    "    election_name = fname.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "    if election_name in elections: \n",
    "        continue\n",
    "\n",
    "    elections.append(election_name)\n",
    "    file_names.append(fname)\n",
    "    profiles.append(ProfileWithTies.read(fname))\n",
    "    \n",
    "for fname in tqdm(glob.glob(\"real_elections/preflib_dataset/*.toi\")):\n",
    "\n",
    "    election_name = fname.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "    if election_name in elections: \n",
    "        continue\n",
    "\n",
    "    elections.append(election_name)\n",
    "    file_names.append(fname)\n",
    "    profiles.append(ProfileWithTies.read(fname))\n",
    "\n",
    "for fname in tqdm(glob.glob(\"real_elections/preflib_dataset/*.toc\")):\n",
    "\n",
    "    election_name = fname.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "    if election_name in elections: \n",
    "        continue\n",
    "\n",
    "    elections.append(election_name)\n",
    "    file_names.append(fname)\n",
    "    profiles.append(ProfileWithTies.read(fname))\n",
    "\n",
    "find_violations(profiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIVS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b63547ec284225b0b714287f01f060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22477 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c855e4b015d473c9504dc7ade1f5ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22477 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590 out of 1883 profiles have no absolute majority winner: 0.3133297928836962\n",
      "\n",
      "Type 1: Original Profile Violations\n",
      "339 violations out of 590 profiles: 0.5745762711864407\n",
      "\n",
      "Type 2: Modified Profile Violations\n",
      "114 violations out of 590 profiles: 0.19322033898305085\n",
      "\n",
      "Total Violations\n",
      "453 violations out of 590 profiles: 0.7677966101694915\n"
     ]
    }
   ],
   "source": [
    "# read a json file\n",
    "import json\n",
    "profiles = []\n",
    "_civs_elections = json.load(open(\"real_elections/civs_dataset/2024-12-15.json\"))\n",
    "\n",
    "civs_elections = _civs_elections['elections']\n",
    "profiles = []\n",
    "for election in tqdm(civs_elections):\n",
    "    if election[\"test\"] == \"yes\":\n",
    "        continue\n",
    "    ballots = []\n",
    "    num_candidates = election['num_choices']\n",
    "    for b in election['ballots']:\n",
    "        ballots.append({cand: rank for cand, rank in enumerate(b) if rank != \"?\"})\n",
    "    profiles.append(ProfileWithTies(ballots, candidates=list(range(num_candidates))))\n",
    "    \n",
    "find_violations(profiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otis 2022 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a383634db9ab43658ef94d1e8a331ff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/458 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a97391d65c8486288f56a181637a321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/458 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This will take about 17 minutes to run\n",
    "\n",
    "items_to_skip = [\n",
    "    '\"skipped', \n",
    "    'overvote', \n",
    "    'undervote']\n",
    "\n",
    "profiles = []\n",
    "enames = []\n",
    "for file in tqdm(glob.glob(\"real_elections/otis_2022_dataset/*.zip\")):\n",
    "\n",
    "    if not file.endswith(\".csv\") and not file.endswith(\".zip\"):\n",
    "        continue\n",
    "    # if file ends with .zip unzip the file and process it \n",
    "    if file.endswith(\".zip\"):\n",
    "        with ZipFile(file, 'r') as zip_ref:\n",
    "            # Iterate through each file inside the zip\n",
    "            for name in zip_ref.namelist():\n",
    "                # Only process .csv files\n",
    "                if name.endswith(\".csv\"):\n",
    "                    with zip_ref.open(name) as f:\n",
    "                        # Read the CSV data into memory\n",
    "                        csv_bytes = f.read()\n",
    "                        # Decode bytes to string\n",
    "                        csv_text = csv_bytes.decode('utf-8')\n",
    "                        # Create a file-like StringIO object\n",
    "                        csv_buffer = io.StringIO(csv_text)\n",
    "                        \n",
    "                        # Now pass this StringIO to ProfileWithTies.read\n",
    "                        prof = ProfileWithTies.read(\n",
    "                            csv_buffer,\n",
    "                            file_format='csv',\n",
    "                            csv_format='rank_columns',\n",
    "                            items_to_skip=items_to_skip\n",
    "                        )\n",
    "                        enames.append(name)\n",
    "                        profiles.append(prof)\n",
    "                        \n",
    "find_violations(profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
